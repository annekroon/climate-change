{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50d3bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bson import json_util\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4133c",
   "metadata": {},
   "source": [
    "### Climate-change issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b740dc1b",
   "metadata": {},
   "source": [
    "#### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef1523e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38277"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data = []\n",
    "\n",
    "for i in range(1, 384):\n",
    "    try: \n",
    "        with open(f'../data/get-twitter-data/convos-climate-change-2020-2021/convo_{i}.json') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            f_data.append(ast.literal_eval(data))\n",
    "    except:\n",
    "        print(i)\n",
    "\n",
    "flat_data = [item for sublist in f_data for item in sublist]\n",
    "len(flat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d113ea",
   "metadata": {},
   "source": [
    "#### Some cleaning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eadc9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meta': {'result_count': 0}}\n",
      "after removing bad entries we keep 10758 data points\n",
      "Fianlly keeping  10461 data points\n"
     ]
    }
   ],
   "source": [
    "print( flat_data[2]) #some errors while making API requests; remove those\n",
    "\n",
    "short_list = [ x for x in flat_data if x != flat_data[2]]\n",
    "print(f\"after removing bad entries we keep {len(short_list)} data points\")\n",
    "\n",
    "clean_short_list = [x for x in short_list if 'data' in x if 'meta' in x]   ## keep only data points that have 'data' and 'meta' included\n",
    "short_results = [x for x in clean_short_list if \"next_token\" not in x['meta']]  ## disregard long conversations\n",
    "\n",
    "print(f\"Fianlly keeping  {len(short_results)} data points\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9def7",
   "metadata": {},
   "source": [
    "####  keep starting tweets that contain the key word (double check as the API should have only provided those)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "febfcd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_tweets = []\n",
    "\n",
    "for x in flat_data:\n",
    "    try:\n",
    "        for i in x['includes']['tweets']:\n",
    "            if 'referenced_tweets' not in i:\n",
    "                if i['text'].lower().count('klimaatverandering') > 0:\n",
    "                    starting_tweets.append(i)\n",
    "                    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f77805bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7976"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(starting_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc611a8",
   "metadata": {},
   "source": [
    "#### Create final list of conversation ids to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4675120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7899\n"
     ]
    }
   ],
   "source": [
    "convos = list( set([x['conversation_id'] for x in starting_tweets])) \n",
    "print(len(convos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc23d7e",
   "metadata": {},
   "source": [
    "#### Filter the data so to only keep data points with a valid conversation Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3deb5d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replies(collection, conId):\n",
    "\n",
    "    '''get replies to valid Conversation Ids'''\n",
    "    \n",
    "    for x in collection:\n",
    "        if x['data'][0]['conversation_id'] == conId: \n",
    "            return x\n",
    "\n",
    "results = [ get_replies(short_results, conId) for conId in convos ] ## calling the function on `short_results` ; our 'cleaned' data\n",
    "results = [x for x in results if x is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc4b61c",
   "metadata": {},
   "source": [
    "### Set of functions to match author of the \"mother\" tweet with replies \n",
    "In addition, a dict is created to look up the names of the users by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b6edac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_author_id(entry_number, results):\n",
    "\n",
    "    for i in results[entry_number]['includes']['tweets']:\n",
    "        if 'referenced_tweets' not in i: \n",
    "            if i['text'].lower().count('klimaatverandering') > 0:\n",
    " \n",
    "                return i['author_id'], i['text']\n",
    "\n",
    "def get_direct_replies(entry_number, results):\n",
    "\n",
    "    direct_replies = []\n",
    "    names = []\n",
    "    ids = []\n",
    "\n",
    "    author_id, author_text  = get_author_id(entry_number, results)\n",
    "\n",
    "    for _ in range(0, len(results[entry_number]['data']) ): \n",
    "        \n",
    "        try:\n",
    "            ids.append(results[entry_number]['includes']['users'][_]['id'])\n",
    "            names.append(results[entry_number]['includes']['users'][_]['username'])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "      #if results[entry_number]['data'][_]['in_reply_to_user_id'] == author_id : ##in reply to \"mother\" tweet;\n",
    "             \n",
    "        if results[entry_number]['data'][_]['author_id'] != author_id: ##if rely is NOT by the author of the \"mother\" (in that case its a thread)\n",
    "            direct_replies.append( results[entry_number]['data'][_])\n",
    "\n",
    "    return direct_replies[::-1], author_id, author_text, dict(zip(ids, names))\n",
    "\n",
    "def get_unique_ids_replies(direct_replies):\n",
    "\n",
    "    '''Check the number of unique user IDs in the replies. \n",
    "    in a next step, we will only keep conversations in which N unique individuals have responded.''' \n",
    "\n",
    "    unique_ids_replies = []\n",
    "\n",
    "    for _ in range(0, len(direct_replies)):\n",
    "\n",
    "        unique_ids_replies.append(len(set([direct_replies[_][i]['author_id'] for i in range(0, len(direct_replies[_])) ] ) ))\n",
    "    \n",
    "    return unique_ids_replies\n",
    "\n",
    "def keep_conversations_with_N_authors(i):\n",
    "    \n",
    "    unique_ids_replies = get_unique_ids_replies([ get_direct_replies(_, results)[0] for _ in range(0, len(results)) ])\n",
    "    \n",
    "    d_replies = [ get_direct_replies(_, results)[0] for _ in range(0, len(results)) ]\n",
    "    author_id = [ get_direct_replies(_, results)[1] for _ in range(0, len(results)) ]\n",
    "    author_text = [ get_direct_replies(_, results)[2] for _ in range(0, len(results)) ]\n",
    "    usernames = [ get_direct_replies(_, results)[3] for _ in range(0, len(results)) ]\n",
    "\n",
    "    ## keep if n=2; that means 2 unique user ids should be in the replies.\n",
    "    ### if len(d) > 2 if len(d) < 11: keep conversations that are between 2 and 11 replies long.\n",
    "\n",
    "    return [(n, d, a_id, a_text)[i] for n, d, a_id, a_text in zip(unique_ids_replies, d_replies, author_id, author_text) if n==2 if len(d) > 2 if len(d) < 11], usernames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011b675",
   "metadata": {},
   "source": [
    "#### Calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b85c2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n"
     ]
    }
   ],
   "source": [
    "d_replies = keep_conversations_with_N_authors(1)[0]\n",
    "author_id = keep_conversations_with_N_authors(2)[0]\n",
    "author_text = keep_conversations_with_N_authors(3)[0]\n",
    "usernames = keep_conversations_with_N_authors(3)[1]\n",
    "\n",
    "assert len(d_replies) == len(author_id) == len(author_text) \n",
    "print(len(d_replies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "522f185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### populate the dict to look up usernames\n",
    "\n",
    "f_usernames = {}\n",
    "for d in usernames:\n",
    "    f_usernames.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba85e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 178, 4: 77, 7: 12, 5: 26, 6: 17, 8: 1, 10: 4, 9: 7})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([len(x) for x in d_replies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6436315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n"
     ]
    }
   ],
   "source": [
    "def get_camera_ready(entry_number):\n",
    "\n",
    "    string_text = f\"**************************\\n\\n\\n{f_usernames[author_id[entry_number]]} (start tweet)\\n\" + author_text[entry_number]\n",
    "    for _ in range(0, len(d_replies[entry_number])):\n",
    "        string_text = string_text + \"\\n\\n\" + f\"{f_usernames[ d_replies[entry_number][_]['author_id'] ]} (reply created at: {d_replies[entry_number][_]['created_at']}\\n\" \n",
    "        string_text = string_text + d_replies[entry_number][_]['text']+ \"\\n\"\n",
    "    return string_text.encode('utf-8', 'replace').decode()\n",
    "\n",
    "res_ = [get_camera_ready(i) for i in range(0, len(d_replies)) ]\n",
    "print(len(res_))\n",
    "\n",
    "with open('climate-change-conversations-24.txt', 'w') as f:\n",
    "    for line in res_:\n",
    "        f.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88669ec",
   "metadata": {},
   "source": [
    "### write data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58ec0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "for entry_number in range(0, len(d_replies)):\n",
    "    my_dict[entry_number] = {\n",
    "                   'starting-tweet': author_text[entry_number], \n",
    "                    'screenname-first-author':f_usernames[author_id[entry_number]], \n",
    "                   'replies' : [d_replies[entry_number][_]['text'] for _ in range( 0, len(d_replies[entry_number]))] ,\n",
    "                   'screennames-replies:' : [ f_usernames[ d_replies[entry_number][_]['author_id']]  for _ in range( 0, len(d_replies[entry_number]))]   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cdcc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('climate-24.json', 'w') as fp:\n",
    "    json.dump(my_dict, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
