{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "sys.path.insert(1, '../../src/')\n",
    "from config import bearer_key\n",
    "from conversationgrabber import Convo_grabber\n",
    "from bson import json_util\n",
    "import collections\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82461f",
   "metadata": {},
   "source": [
    "### Grab conversations from twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://api.twitter.com/2/tweets/search/all?&\"\n",
    "EXTENDED_URL =  \"tweet.fields=author_id,conversation_id,created_at,in_reply_to_user_id,referenced_tweets&expansions=author_id,in_reply_to_user_id,referenced_tweets.id&user.fields=name,username\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Convo_grabber(bearer_key = bearer_key, start_date=\"2021-10-01\", end_date=\"2022-10-01\", BASE_URL = BASE_URL, EXTENDED_URL = EXTENDED_URL )\n",
    "results = a.get_conversation_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29b0572",
   "metadata": {},
   "source": [
    "### Save results to `json` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(results, default=json_util.default)\n",
    "with open('conversation-ids-climate-change.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e690e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open again if needed...\n",
    "with open('conversation-ids-climate-change.json') as json_file:\n",
    "    results = ast.literal_eval(json.load(json_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1790f",
   "metadata": {},
   "source": [
    "### Keep only the conversation id's that indicate an actual conversation\n",
    "For now, i've selected the `ids` that occur more than 3 times in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553cc746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209616\n"
     ]
    }
   ],
   "source": [
    "ids_ = [item for sublist in [x['conversation_ids'] for x in results ] for item in sublist]# Put all conversation ids in a flat list\n",
    "conversations = list(set([x for x, y in collections.Counter(ids_).items()]))\n",
    "print(len(conversations)) # number of conversations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f67c473",
   "metadata": {},
   "source": [
    "## Retrieve conversations based on ids from the Twitter API\n",
    "I'm retrieving data in chunks of 100 conversation ids due to time-out issues; additionally--`sleep` time is needed to avoid making to many requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_strptime(date):\n",
    "        '''takes date (str) and returns dt formats that can be used to query the Twitter API date \n",
    "        should be in the format: yyyy-m-d e.g., 2022-9-30'''\n",
    "        \n",
    "        return datetime.strptime(f\"{date.split('-')[0]}-{date.split('-')[1]}-{date.split('-')[2]}T00:00:00Z\", dtformat).strftime(dtformat)\n",
    "\n",
    "dtformat = '%Y-%m-%dT%H:%M:%SZ'\n",
    "start_time = get_strptime('2015-1-10')\n",
    "end_time = get_strptime('2022-10-10')\n",
    "\n",
    "def get_parameters(start_date, end_date, conversations_id):\n",
    "    query_params = {'query': f\"conversation_id:{conversations_id}\", \n",
    "    \"max_results\": \"100\" , \n",
    "    \"start_time\" : start_time, \n",
    "    \"end_time\" : end_time}\n",
    "    return query_params\n",
    "\n",
    "\n",
    "n = 100\n",
    "chunks = [conversations[i:i + n] for i in range(0, len(conversations), n)]\n",
    "\n",
    "#f_data = []\n",
    "number = 65\n",
    "\n",
    "for chunk in tqdm(chunks[65:]):\n",
    "    number = number + 1\n",
    "    data = [] \n",
    "\n",
    "    for id in chunk:\n",
    "        time.sleep(5)\n",
    "    \n",
    "        response = requests.get(f\"{BASE_URL}{EXTENDED_URL}\",  headers={\"Authorization\": f\"Bearer {bearer_key}\",  \"User-Agent\" : \"v2FullArchiveSearchPython\"}, params = get_parameters(start_time, end_time, id))\n",
    "        print(f\"response status: {response.status_code}\")\n",
    " \n",
    "        if response.json() != \"{'meta': {'result_count': 0}}\":\n",
    "            data.append(response.json()) \n",
    "\n",
    "        json_string = json.dumps(data, default=json_util.default)\n",
    "        \n",
    "        with open(f'conversations-new/convo_{number}.json', 'w') as outfile:\n",
    "            json.dump(json_string, outfile)\n",
    "\n",
    "    f_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data = [item for sublist in f_data for item in sublist]\n",
    "len(flat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b740dc1b",
   "metadata": {},
   "source": [
    "### read data in if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef1523e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35345"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data = []\n",
    "for i in range(1, 357):\n",
    "\n",
    "    with open(f'conversations-new/convo_{i}.json') as json_file:\n",
    "        try: \n",
    "            data = json.load(json_file)\n",
    "            f_data.append(ast.literal_eval(data))\n",
    "        except:\n",
    "            print(i)\n",
    "\n",
    "flat_data = [item for sublist in f_data for item in sublist]\n",
    "len(flat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "febd0e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6195\n"
     ]
    }
   ],
   "source": [
    "short_list = [ x for x in flat_data if x != flat_data[1]]\n",
    "print(len(short_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9def7",
   "metadata": {},
   "source": [
    "### retrieve starting tweets that contain the key word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "febfcd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_tweets = []\n",
    "\n",
    "for x in short_list:\n",
    "    try:\n",
    "        for i in x['includes']['tweets']:\n",
    "            if 'referenced_tweets' not in i:\n",
    "                if i['text'].lower().count('klimaatverandering') > 1:\n",
    "                    starting_tweets.append(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc611a8",
   "metadata": {},
   "source": [
    "### remove \"thread\" type starting tweets (in order to only model conversations to a single tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4675120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "duplicates = [item for item, count in collections.Counter([x['conversation_id'] for x in starting_tweets]).items() if count > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be78f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convos = [x['conversation_id'] for x in starting_tweets]\n",
    "convos = [x for x in convos if x not in duplicates]\n",
    "len(convos) == len(set(convos))\n",
    "len(convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3deb5d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replies(collection, conId):\n",
    "    for x in collection:\n",
    "        if x['data'][0]['conversation_id'] == conId: \n",
    "            return x\n",
    "\n",
    "results = [ get_replies(short_list, conId) for conId in convos ]\n",
    "results = [x for x in results if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fc0ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_id(entry_number, results):\n",
    "    for i in results[entry_number]['includes']['tweets']:\n",
    "        if 'referenced_tweets' not in i: \n",
    "            if i['text'].lower().count('klimaatverandering') > 1:\n",
    "                return i['author_id'], i['text']\n",
    "\n",
    "def get_direct_replies(entry_number, results):\n",
    "    direct_replies = []\n",
    "    author_id, author_text = get_author_id(entry_number, results)\n",
    "\n",
    "    for _ in range(0, len(results[entry_number]['data']) ): \n",
    "        if results[entry_number]['data'][_]['in_reply_to_user_id'] == author_id :\n",
    "            direct_replies.append( results[entry_number]['data'][_]) \n",
    "\n",
    "    return direct_replies[::-1][:10], author_id, author_text\n",
    "\n",
    "d_replies = [ get_direct_replies(_, results)[0] for _ in range(0, len(results)) ]\n",
    "author_id = [ get_direct_replies(_, results)[1] for _ in range(0, len(results)) ]\n",
    "author_text = [ get_direct_replies(_, results)[2] for _ in range(0, len(results)) ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6436315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "def get_camera_ready(entry_number):\n",
    "\n",
    "    string_text = f\"*************************\\nAUTHOR FIRST TWEET: {author_id[entry_number]} \\n\" + author_text[entry_number]\n",
    "    for _ in range(0, len(d_replies[entry_number])):\n",
    "        string_text = string_text + \"\\n\\n\" + f\"REPLY AUTHOR {_}, ID: {d_replies[entry_number][_]['author_id']}, CREATED AT: {d_replies[entry_number][_]['created_at']}\\n\" \n",
    "        string_text = string_text + d_replies[entry_number][_]['text']+ \"\\n\"\n",
    "    return string_text.encode('utf-8', 'replace').decode()\n",
    "\n",
    "res_ = [get_camera_ready(i) for i in range(0, len(results)) ]\n",
    "print(len(res_))\n",
    "\n",
    "with open('climate-change-conversations.txt', 'w') as f:\n",
    "    for line in res_:\n",
    "        f.write(f\"r{line}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
